---
title: RoBERTa__A_Robustly_Optimized_BERT_Pretraining_Approach
date: 2019-07-26 00:00:00 +0800
categories: ['RoBERTa']
tags: ['RoBERTa']
---

- 📙Paper: "[Unleashing the potential of prompt engineering in Large Language Models: a comprehensive review](https://www.semanticscholar.org/paper/Unleashing-the-potential-of-prompt-engineering-in-a-Chen-Zhang/595c8d39a6155354fd7d8f62a4441be5c82e68da)"
- 🔑Public: ✅
- ⚲ area: Roberta
- 📅 Date: 2019-07-26
- 🔎 Taxonomy: fine-tuning
- 📝 #References: 68
