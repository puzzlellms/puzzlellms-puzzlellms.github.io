---
title: RoBERTa
date: 2019-07-26 00:00:00 +0800
categories: [model]
tags: [fine-tuning, model, roberta]
---

- 📙Paper: "[RoBERTa: A Robustly Optimized BERT Pretraining Approach](https://www.semanticscholar.org/paper/RoBERTa%3A-A-Robustly-Optimized-BERT-Pretraining-Liu-Ott/077f8329a7b6fa3b7c877a57b81eb6c18b5f87de)"
- 🔑Public: ✅
- ⚲ Area: Model
- 📅 Date: 2019-07-26
- 🔎 Paper Section: methods / fine-tuning
- 📝 References: 68
