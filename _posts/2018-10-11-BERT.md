---
title: BERT
date: 2018-10-11 00:00:00 +0800
categories: [model]
tags: [fine-tuning, model, bert]
---

- 📙Paper: "[BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding](https://www.semanticscholar.org/paper/BERT%3A-Pre-training-of-Deep-Bidirectional-for-Devlin-Chang/df2b0e26d0599ce3e70df8a9da02e51594e0e992)"
- 🔑Public: ✅
- ⚲ Area: Model
- 📅 Date: 2018-10-11
- 🔎 Paper Section: methods / fine-tuning
- 📝 References: 63
